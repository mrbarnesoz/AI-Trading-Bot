Metadata-Version: 2.4
Name: ai-trading-bot
Version: 0.1.0
Summary: AI-assisted trading bot with data pipeline, ML model training, and backtesting utilities.
Author: AI Trading Bot Maintainers
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.24
Requires-Dist: pandas>=2.0
Requires-Dist: scikit-learn>=1.3
Requires-Dist: yfinance>=0.2.30
Requires-Dist: pyyaml>=6.0
Requires-Dist: joblib>=1.3
Requires-Dist: duckdb>=0.9
Requires-Dist: httpx>=0.24
Requires-Dist: polars>=0.20
Requires-Dist: prefect>=2.14
Requires-Dist: streamlit>=1.32
Requires-Dist: fastapi>=0.110
Requires-Dist: uvicorn[standard]>=0.23
Requires-Dist: gradio>=4.0
Requires-Dist: websocket-client>=1.6
Requires-Dist: prometheus-client>=0.17
Requires-Dist: flask>=2.3
Provides-Extra: dev
Requires-Dist: pytest>=7.4; extra == "dev"
Requires-Dist: pytest-cov>=4.1; extra == "dev"
Requires-Dist: black>=23.7; extra == "dev"
Requires-Dist: ruff>=0.1.9; extra == "dev"

# AI Trading Bot

An end-to-end reference implementation of an AI-assisted trading bot. The app provides utilities to download OHLCV data (BitMEX compatible), engineer indicator features, train a machine learning model, and evaluate strategy performance via vectorised backtesting.

> Keep this README up to date whenever you change the bot or its tooling.

## Key capabilities
- Automated BitMEX OHLCV and funding downloads with on-disk caching to speed up reruns.
- Feature engineering for SMA, EMA, RSI, MACD, volatility, volume, and funding-derived metrics.
- Random forest classifier trained to predict the next-period direction with configurable thresholds.
- Adaptive mode selector that switches between scalping, intraday, and swing regimes.
- Probability-driven signal generation with banded sizing rules and trailing stop integration.
- Backtesting module with costs, Sharpe ratio, win-rate, drawdown, and capital utilisation reporting.
- Clear Streamlit user interface with guided workflows, scenario buttons, and spelled-out terminology.

## Project structure
```
|-- config.yaml              # Central configuration for data, model, and strategy
|-- pyproject.toml           # Python project metadata and dependencies
|-- scripts/                 # Convenience entrypoints for common workflows
|-- src/ai_trading_bot/      # Core package code (data, features, model, strategy, backtest)
|-- data/                    # Cached raw/processed data (ignored by git)
|-- models/                  # Persisted model artifacts (ignored by git)
|-- logs/                    # Log output (ignored by git)
|-- results/                 # Backtest summaries, QC reports, etc.
`-- tests/                   # Pytest-based unit tests
```

## Getting started
1. **Prerequisites**
   - Python 3.11 (or newer 3.10+) with pip
   - PowerShell 7+ on Windows for the RunBot scripts
   - Optional: Git for version control

2. **Create a virtual environment**
   ```powershell
   python -m venv .venv
   .\.venv\Scripts\Activate.ps1  # use source .venv/bin/activate on macOS/Linux
   ```

3. **Install dependencies**
   ```powershell
   python -m pip install --upgrade pip
   python -m pip install -r requirements.txt
   ```
   Developers can use `python -m pip install -e .[dev]` for editable installs.

4. **(Optional) Configure VS Code**
   - Open the project folder in VS Code.
   - Select the interpreter at `.venv\Scripts\python.exe`.
   - Use the provided tasks (`Terminal > Run Task...`) for training, backtesting, or running tests.

## Flash up the bot (Windows quick launch)
The RunBot scripts start everything (Prefect server, worker, and the Flask control panel) and shut it down again.

1. Install PowerShell 7+ and Python 3.11 if you have not already.
2. From the repo root run:
   ```powershell
   .\RunBot.bat
   ```
   The script builds the virtual environment, deploys Prefect flows (including the new auto-strategy flow), and launches the Flask UI at http://127.0.0.1:5000.
3. To stop services run:
   ```powershell
   .\RunBot.ps1 -Stop
   ```
4. Optional switches in `RunBot.ps1`:
   - `-DebugMode` streams log tails and enables verbose Prefect logging.
   - `GuiMode` defaults to `flask` but you can still switch to `streamlit`, `fastapi`, or `gradio`.
   - Logs live under `logs/` (one file per service).

Prefect deployments are defined in `prefect.yaml`. After editing flows, run `prefect deploy --prefect-file prefect.yaml --all` and keep a worker alive with `prefect worker start --pool bitmex`.

### Control Center overview
- The new React + Tailwind SPA renders a live strategy grid (Sharpe, trades, win rate, drawdown) per symbol, with filters for under-performers and one-click promotion to the active `config.yaml`.
- Backtest management lets you queue multi-strategy sweeps, annotate start/end windows, and review guardrail breaches or result snapshots directly from `results/ui/backtest/`.
- Inline config editing surfaces guardrail warnings before you save, with revert buttons and automatic JSON/CSV snapshots of promotions under `results/promotions/`.
- System controls now expose a kill switch, orchestrator restart, learning toggles, and TradingView ingestion status; alerts are pinned to a persistent notification bar so you never miss a degradation warning.
- A dedicated Kafka & feeds card surfaces container health and gives start/stop/restart controls; the UI mirrors Docker status and warns when the broker is offline.

### Ingestion & external signals
1. **Kafka + DuckDB bridge**
   ```powershell
   docker compose -f docker/docker-compose.kafka.yml up -d
   ```
   The compose file launches Zookeeper and Kafka (Confluent 7.5.x). Messages land in the `logs/` fallback if Kafka is unreachable. `RunBot.ps1` now runs the same command automatically (creating the `kafka-net` bridge if needed) unless `RUNBOT_SKIP_KAFKA=1` is set in your environment.
2. **Windows environment variables (PowerShell 7+)**
   ```powershell
   $env:KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"
   $env:TRADINGVIEW_SHARED_SECRET = "dev-shared-secret"
   $env:TRADINGVIEW_TOPIC = "tradingview.alerts"
   $env:SENTIMENT_TOPIC = "sentiment.signals"
   ```
   Replace the values to match your cluster/secrets. Use `Get-ChildItem Env:` to confirm.
3. **TradingView alerts** post JSON to `http://<host>:5000/api/feeds/alerts` with the matching `secret`. The webhook forwards alerts to Kafka and appends them to DuckDB (`warehouse.duckdb`) for the learning pipeline.

## Usage
Run all commands from the project root with your virtual environment activated.

Example data stanza (`config.yaml`):
```yaml
data:
  source: "bitmex"
  symbol: "XBTUSD"
  interval: "1h"
  start_date: "2024-01-01T00:00:00Z"
  end_date: null
  cache_dir: "data/raw"
```

- **Prime the BitMEX cache**
  ```powershell
  python -m ai_trading_bot download --force
  ```
  The `--force` flag refreshes the raw CSV in `data/raw/bitmex_<symbol>_<interval>_*.csv`. Omit the flag to reuse the cached file. `scripts/download_data.py` exposes the same functionality if you prefer a lightweight wrapper.

- **Train the model**
  ```powershell
  python -m ai_trading_bot train --force-download
  ```
  The training run rebuilds the engineered dataset in `data/engineered/` (Parquet + CSV), fits the random forest, and writes artifacts to `models/price_direction_model.joblib` plus `models/latest_metadata.json`.

- **Backtest the strategy**
  ```powershell
  python -m ai_trading_bot backtest
  ```
  Backtest logs now highlight `trades_count`, `avg_holding_bars`, and `gross_exposure_avg` alongside the original metrics. Use `--force-download` if you need to refresh the underlying OHLCV prior to backtesting.
- **Backtest multiple symbols with exposure caps**
  ```powershell
  python scripts/backtest_multi.py --symbols XBTUSD ETHUSD --max-cap 0.5
  ```
  The script fans out the configured pipeline per symbol, enforces the portfolio capital limit, and writes an aggregate summary to `results/multi_backtest_<timestamp>.json`. Include `--force-download` to refresh each dataset before testing.
- **Run automated strategy research**
  ```powershell
  python scripts/auto_research.py --symbols XBTUSD ETHUSD --timeframes 1h --top-k 2
  ```
  Generates a consolidated report under `results/auto/` with the top Sharpe candidates per symbol/timeframe (the `--min-trades` threshold is configurable).
- **Run walk-forward validation**
  ```powershell
  python scripts/backtest_walk_forward.py --train-days 120 --test-days 30 --step-days 30
  ```
- **Run automated strategy research**
  
  This retrains the model on each rolling window, evaluates on the following test window, and reports per-segment and aggregated metrics so you can check robustness before going live.
- **Run the live controller (paper or live)**
  Generates a consolidated report under  with the top Sharpe candidates per symbol/timeframe (min trades configurable).
  ```powershell
  python scripts/live_run.py --symbols XBTUSD --testnet --dry-run --contract-size 100 --metrics-port 9001
  The live engine now uses the multi-strategy orchestrator to toggle between momentum, breakout, and mean-reversion modules per symbol, logging the active strategy/regime for each trade.
  ```
  This wires the websocket feed, ML strategy engine, risk manager, and execution router together. Provide `BITMEX_API_KEY` / `BITMEX_API_SECRET` env vars, drop `--dry-run`, and remove `--testnet` to trade on mainnet once you are ready.
- **Expose metrics & dashboards** â€“ Prometheus/Grafana setup instructions and a starter dashboard live under `monitoring/README.md`.
- **Launch the web UI (Flask + Bootstrap)**
  ```powershell
  python run.py
  ```
  The control panel is served at `http://localhost:5000`. Manage strategies, edit configs, monitor logs, and trigger training/backtests from the browser.
- **Prototype strategy weighting with RL**
  ```powershell
  python scripts/rl_backtest.py --mode weight --weights "trend=0.7,mean_reversion=0.3" "trend=0.5,mean_reversion=0.5"
  ```
  The RL environment tests each weight combination (or threshold adjustments in `--mode threshold`) and reports rewards so you can promote the best performer into the live controller via `--strategy-weights`.
- **Probe RL/meta-learning reward surfaces**
  ```powershell
  python scripts/rl_backtest.py --actions "0.00:0.00 0.02:-0.02 -0.02:0.02"
  ```
  Each action adjusts the long/short thresholds by the specified deltas and records reward, summary stats, and metadata in `results/rl_backtest_<timestamp>.json`. Use this to prioritise which threshold shifts are worth deeper RL exploration.
- **Run an ATR / trailing sweep**
  ```powershell
  python tools/run_sweep.py configs\xbtusd_1h_maker_swing.yaml
  ```
  The helper runs the grid defined in `src/ai_trading_bot/experiments/atr_sweep.py` and writes a timestamped CSV under `sweeps/`. The snapshot config ships in `configs/xbtusd_1h_maker_swing.yaml`; duplicate and tweak it for other markets before sweeping.

- **Run tests**
  ```powershell
  python -m pytest
  ```

## Kafka ingestion & feeds
1. Copy .env.example to .env and set broker credentials (KAFKA_BOOTSTRAP_SERVERS, TLS paths if required).
2. Start the local broker (optional) with docker compose -f docker/docker-compose.kafka.yml up -d.
3. Verify the topics exist:
   `powershell
   docker compose -f docker/docker-compose.kafka.yml exec kafka kafka-topics.sh --bootstrap-server localhost:9092 --list
   `
4. Run .\RunBot.bat so the ingestion services pick up the environment variables.

The TradingView webhook listens on POST /api/feeds/alerts. Include the shared secret and your alert payload; it is forwarded to Kafka (topic 	radingview.alerts) and DuckDB 
aw_feeds.feed_events automatically.

### Sentiment ingestion
- Configure a provider via .env (default ile, supported 
ewsapi).
- python ingestion/sentiment_collector.py polls the provider, publishes scored sentiment to Kafka (sentiment.signals), and mirrors it into DuckDB for offline training.
- Without live credentials the collector falls back to data/sentiment/headlines.json.

## Latency arbitrage validation
- Generate a latency-arb summary with:
  `powershell
  python analysis/latency_arbitrage_sim.py
  `
  This writes 
esults/latency_arbitrage/latency_arbitrage_summary.json and a guardrail snapshot in logs/latency_arbitrage_guardrail.json.
- Enable the strategy by setting 
isk.latency_arb.enabled: true in config.yaml and adjusting thresholds (min_average_bps, min_trades).
- Guardrails block execution until the sim reports positive net P&L and sufficient average edge; violations surface in the dashboard export/guardrail panels.
## Risk Guardrails
- The dashboard guardrail card lists each configuration, highlights violations, and offers one-click diagnostics export / rollback.
- Core configuration values are validated against safe ranges (capital fractions, slippage assumptions, and max loss percentages).
- Training/backtests abort with clear messages if guardrails are tripped.
- Live trading is only permitted after a recent paper session (within 6 hours) and uses the validated config.

## Notes
- Configuration lives in `config.yaml`; update symbols, intervals, thresholds, or trailing settings there.
- Signal filters now support `hysteresis_k_atr` to enforce ATR-based persistence before flips.
- Quality check results are written to `results/qc_summary.json` and are surfaced in the Control Center.
- The live agent can be started manually with:
  ```powershell
  prefect worker start --pool "bitmex"
  python -m deployment.live_agent_runner --config conf/live_agent.yaml --api-client live.execution.bitmex:BitmexClient
  ```
  Update the Control Center wizard after starting or stopping the agent so the dashboard stays accurate.

